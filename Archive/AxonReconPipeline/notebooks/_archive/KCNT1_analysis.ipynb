{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sravy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# '''create new ipython kernel if needed'''\n",
    "# !python -m ipykernel install --user --name=axonenv\n",
    "'''check python interpreter path'''\n",
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.append('/home/adam/MEA_Analysis/AxonReconPipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "import statsmodels.stats.multitest as mt\n",
    "import logging\n",
    "import ast\n",
    "import pingouin as pg\n",
    "\n",
    "color_map = {'WT': '#0000FF', 'Het': '#FF0000', 'Homo': '#FFA500'}\n",
    "\n",
    "\n",
    "# Logging setup\n",
    "#reset logger\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)  # Create a logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()  # Create handlers, logs to console\n",
    "#stream_handler.setLevel(logging.DEBUG)  # Set level of handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s - %(module)s.%(funcName)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)  # Add handlers to the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat data\n",
    "def count_units_and_branches(data):\n",
    "    \"\"\"Count units and branches grouped by DIV and Category.\"\"\"\n",
    "    unit_count = 0\n",
    "    branch_count = 0\n",
    "    for df in data:\n",
    "        required_columns = ['DIV', 'Category', 'unit_ids', 'branch_id']\n",
    "        if not all(column in df.columns for column in required_columns):\n",
    "            raise ValueError(f\"Data must contain the following columns: {required_columns}\")\n",
    "    \n",
    "        unit_count += len(df['unit_ids'].index)\n",
    "        branch_counts = [len(eval(branch_list)) for branch_list in df['branch_id']]\n",
    "        branch_count += sum(branch_counts)\n",
    "\n",
    "    return unit_count, branch_count\n",
    "\n",
    "def validate_template_densities(data, threshold=0.95):\n",
    "    \"\"\"Validate and filter density data based on given criteria.\"\"\"\n",
    "    total_units, total_branches = count_units_and_branches(data)\n",
    "    print('Unvalidated:')\n",
    "    print(f'Total units: {total_units}, Total branches: {total_branches}')\n",
    "    \n",
    "    valid_data = data.copy()\n",
    "    for i, df in enumerate(valid_data):\n",
    "        df['channel_density'] = df['channel_density'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        density_threshold = df['channel_density'].apply(lambda x: x[0]).quantile(threshold)\n",
    "        valid_df = df[df['channel_density'].apply(lambda x: x[0]) >= density_threshold]\n",
    "        valid_df.index = range(len(valid_df))  # Reset index\n",
    "        valid_data[i] = valid_df\n",
    "    \n",
    "    valid_units, valid_branches = count_units_and_branches(valid_data)\n",
    "    print('After density validation:')\n",
    "    print(f'Total units: {valid_units}, Total branches: {valid_branches}')\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def validate_branch_lengths_data(data, stdevs=3):\n",
    "    \"\"\"Validate and filter branch lengths data based on given criteria.\"\"\"\n",
    "    data_copy = data.copy()\n",
    "    total_units, total_branches = len(set(data_copy['unit_ids'])), len(data_copy['branch_id'])\n",
    "    print('Before branch length validation:')\n",
    "    print(f'Total units: {total_units}, Total branches: {total_branches}')\n",
    "    \n",
    "    data_copy['length'] = data_copy['length'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    valid_data = data_copy[data_copy['length'].apply(lambda x: x > 0)]\n",
    "    valid_data = valid_data[np.abs(valid_data['length'] - valid_data['length'].mean()) <= (stdevs * valid_data['length'].std())]\n",
    "\n",
    "    valid_units, valid_branches = len(set(valid_data['unit_ids'])), len(valid_data['branch_id'])\n",
    "    print('After branch length validation:')\n",
    "    print(f'Total units: {valid_units}, Total branches: {valid_branches}')\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def validate_velocity_data(data, stdevs=3):\n",
    "    \"\"\"Validate and filter velocity data based on given criteria.\"\"\"\n",
    "    data_copy = data.copy()\n",
    "    total_units, total_branches = len(set(data_copy['unit_ids'])), len(data_copy['branch_id'])\n",
    "    print('Before velocity validation:')\n",
    "    print(f'Total units: {total_units}, Total branches: {total_branches}')\n",
    "    \n",
    "    data_copy['Velocity'] = data_copy['Velocity'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    valid_data = data_copy[data_copy['Velocity'].apply(lambda x: x > 0)]\n",
    "    valid_data = valid_data[np.abs(valid_data['Velocity'] - valid_data['Velocity'].mean()) <= (stdevs * valid_data['Velocity'].std())]\n",
    "    \n",
    "    valid_units, valid_branches = len(set(valid_data['unit_ids'])), len(valid_data['branch_id'])\n",
    "    print('After velocity validation:')\n",
    "    print(f'Total units: {valid_units}, Total branches: {valid_branches}')\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def validate_number_of_branches_data(data):\n",
    "    \"\"\"Validate and filter number of branches data based on given criteria.\"\"\"\n",
    "    data_copy = data.copy()\n",
    "    total_units, total_branches = len(set(data_copy['unit_ids'])), data_copy['num_branches'].sum()\n",
    "    print('Before number of branches validation:')\n",
    "    print(f'Total units: {total_units}, Total branches: {total_branches}')\n",
    "    \n",
    "    data_copy['branch_id'] = data_copy['branch_id'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    valid_data = data_copy[data_copy['branch_id'].apply(lambda x: len(x) > 0)]\n",
    "    \n",
    "    valid_units, valid_branches = len(set(valid_data['unit_ids'])), valid_data['num_branches'].sum()\n",
    "    print('After number of branches validation:')\n",
    "    print(f'Total units: {valid_units}, Total branches: {valid_branches}')\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def load_data(file_paths, categories, divs):\n",
    "    \"\"\"Load data from CSV files and append category and DIV information.\"\"\"\n",
    "    data = []\n",
    "    for file_path, category, div in zip(file_paths, categories, divs):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Category'] = category\n",
    "        df['DIV'] = div\n",
    "        data.append(df)\n",
    "    return data\n",
    "\n",
    "def extract_branch_lengths(data):\n",
    "    \"\"\"Extract branch lengths for high-density regions with positive velocities.\"\"\"\n",
    "    unit_ids, lengths, categories, DIVs, branch_lists = [], [], [], [], []\n",
    "    unit_count = 0\n",
    "    for df in data:\n",
    "        category, div = df['Category'].iloc[0], df['DIV'].iloc[0]\n",
    "        for unit_id, length_list, velocity_list, density, branch_list in zip(df['unit_ids'], df['length'], df['velocity'], df['channel_density'], df['branch_id']):\n",
    "            length_list = eval(length_list)\n",
    "            branch_lists.extend(eval(branch_list))\n",
    "            unit_ids.extend([unit_count] * len(length_list))\n",
    "            lengths.extend(length_list)\n",
    "            categories.extend([category] * len(length_list))\n",
    "            DIVs.extend([div] * len(length_list))\n",
    "            unit_count += 1\n",
    "    return pd.DataFrame({'unit_ids': unit_ids, 'length': lengths, 'Category': categories, 'DIV': DIVs, 'branch_id': branch_lists})\n",
    "\n",
    "def extract_branch_velocities(data):\n",
    "    \"\"\"Extract branch velocities for high-density regions with positive velocities.\"\"\"\n",
    "    unit_ids, velocities, categories, DIVs, branch_lists = [], [], [], [], []\n",
    "    unit_count = 0\n",
    "    for df in data:\n",
    "        category, div = df['Category'].iloc[0], df['DIV'].iloc[0]\n",
    "        for unit_id, velocity_list, density, branch_list in zip(df['unit_ids'], df['velocity'], df['channel_density'], df['branch_id']):\n",
    "            velocity_list = eval(velocity_list)\n",
    "            branch_lists.extend(eval(branch_list))\n",
    "            unit_ids.extend([unit_count] * len(velocity_list))\n",
    "            velocities.extend(velocity_list)\n",
    "            categories.extend([category] * len(velocity_list))\n",
    "            DIVs.extend([div] * len(velocity_list))\n",
    "            unit_count += 1\n",
    "    return pd.DataFrame({'unit_ids': unit_ids, 'Velocity': velocities, 'Category': categories, 'DIV': DIVs, 'branch_id': branch_lists})\n",
    "\n",
    "def extract_number_of_branches(data):\n",
    "    \"\"\"Extract the number of branches with positive velocities for high-density regions.\"\"\"\n",
    "    unit_ids, num_branches, branches, categories, DIVs = [], [], [], [], []\n",
    "    unit_count = 0\n",
    "    for df in data:\n",
    "        category, div = df['Category'].iloc[0], df['DIV'].iloc[0]\n",
    "        for unit_id, branches_list, velocity_list, density in zip(df['unit_ids'], df['branch_id'], df['velocity'], df['channel_density']):\n",
    "            velocity_list = eval(velocity_list)\n",
    "            branches_list = eval(branches_list)\n",
    "            unit_ids.append(unit_count)\n",
    "            branches.append(branches_list)\n",
    "            categories.append(category)\n",
    "            DIVs.append(div)\n",
    "            num_branches.append(len(branches_list))\n",
    "            unit_count += 1\n",
    "    return pd.DataFrame({'unit_ids': unit_ids, 'num_branches': num_branches, 'branch_id': branches, 'Category': categories, 'DIV': DIVs})\n",
    "\n",
    "def add_significance_annotations(ax, data, y, group_by):\n",
    "    \"\"\"Add significance annotations to the plot.\"\"\"\n",
    "    divs = data['DIV'].unique()\n",
    "    pairs, p_values = [], []\n",
    "\n",
    "    for div in divs:\n",
    "        data_div = data[data['DIV'] == div]\n",
    "        categories = data_div[group_by].unique()\n",
    "        pairs_div = [(cat1, cat2) for i, cat1 in enumerate(categories) for cat2 in categories[i+1:]]\n",
    "        \n",
    "        for (cat1, cat2) in pairs_div:\n",
    "            data1 = data_div[data_div[group_by] == cat1][y]\n",
    "            data2 = data_div[data_div[group_by] == cat2][y]\n",
    "            t_stat, p_val = ttest_ind(data1, data2)\n",
    "            pairs.append((div, cat1, cat2))\n",
    "            p_values.append(p_val)\n",
    "            logger.debug(f'Comparing {cat1} vs {cat2} at DIV {div}: t-statistic={t_stat}, p-value={p_val}')\n",
    "\n",
    "    reject, p_vals_corrected, _, _ = mt.multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "    for (div, cat1, cat2), p_val, reject_h0 in zip(pairs, p_vals_corrected, reject):\n",
    "        if reject_h0:\n",
    "            x1 = list(divs).index(div)\n",
    "            y_max = data[data['DIV'] == div][y].max()\n",
    "            y, h, col = y_max + 1, 1, 'k'\n",
    "            ax.plot([x1 - 0.2, x1 + 0.2], [y + h, y + h], lw=1.5, c=col)\n",
    "            ax.text(x1, y + h, \"*\", ha='center', va='bottom', color=col)\n",
    "            logger.debug(f'Significant difference between {cat1} and {cat2} at DIV {div} after Bonferroni correction: adjusted p-value={p_val}')\n",
    "\n",
    "def plot_with_significance(data, y, title, ylabel, scatter=True):\n",
    "    \"\"\"Plot data with significance annotations and outliers as diamonds.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sorted_data = data[data['Category'].isin(['WT', 'Het', 'Homo'])].copy()\n",
    "    sorted_data['Category'] = pd.Categorical(sorted_data['Category'], categories=['WT', 'Het', 'Homo'], ordered=True)\n",
    "    \n",
    "    palette = [color_map[cat] for cat in sorted_data['Category'].cat.categories]\n",
    "    ax = sns.barplot(x='DIV', y=y, hue='Category', data=sorted_data, palette=palette, alpha=0.6, errorbar='se')\n",
    "    if scatter: sns.stripplot(x='DIV', y=y, hue='Category', data=sorted_data, jitter=True, dodge=True, marker='D', alpha=0.6, palette=palette, ax=ax, edgecolor='gray')\n",
    "    \n",
    "    add_significance_annotations(ax, sorted_data, y, 'Category')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('DIV')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[0:3], labels[0:3], title='Category')\n",
    "    plt.show()\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Validate data through all steps and combine filters\n",
    "def combine_validations(valid_data, stddevs=3):\n",
    "    branch_lengths_data = extract_branch_lengths(valid_data)\n",
    "    branch_velocities_data = extract_branch_velocities(valid_data)\n",
    "    number_of_branches_data = extract_number_of_branches(valid_data)\n",
    "\n",
    "    valid_bl_data = validate_branch_lengths_data(branch_lengths_data, stdevs=3)\n",
    "    valid_velocities_data = validate_velocity_data(branch_velocities_data, stdevs=3)\n",
    "    valid_number_of_branches_data = validate_number_of_branches_data(number_of_branches_data)\n",
    "\n",
    "    # Merge the validated datasets based on unit_ids\n",
    "    merged_data = pd.merge(valid_bl_data, valid_velocities_data, on=['unit_ids', 'Category', 'DIV', 'branch_id'])\n",
    "    #merged_data = pd.merge(merged_data, valid_number_of_branches_data, on=['unit_ids', 'Category', 'DIV', 'branch_id'])\n",
    "    unit_count, branch_count = len(set(merged_data['unit_ids'])), len(merged_data['branch_id'])\n",
    "    print('After merging:')\n",
    "    print(f'Total units: {unit_count}, Total branches: {branch_count}')\n",
    "    print(f'Number of branches per unit: {branch_count / unit_count}')\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/home/adam/workspace/git_workspace/MEA_Analysis/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''get current working directory, change it to project root directory'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/adam/workspace/git_workspace/MEA_Analysis/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Last Updated 28July2024, aw\",\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the uploaded files into dataframes\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# TODO: T5 doesnt have any axontracking, but T6 does and will.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m files_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIV4\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT4\u001b[39m\u001b[38;5;124m\"\u001b[39m: {            \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     }\n\u001b[0;32m    151\u001b[0m }\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/home/adam/workspace/git_workspace/MEA_Analysis/'"
     ]
    }
   ],
   "source": [
    "'''Select axon analytic .csv files to plot/compare'''\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''get current working directory, change it to project root directory'''\n",
    "os.getcwd()\n",
    "os.chdir('/home/adam/workspace/git_workspace/MEA_Analysis/')\n",
    "\n",
    "# Last Updated 28July2024, aw\",\n",
    "# Load the uploaded files into dataframes\n",
    "# TODO: T5 doesnt have any axontracking, but T6 does and will.\n",
    "files_dict = {\n",
    "    \"DIV4\": {\n",
    "        \"T4\": {            \n",
    "            \"files\": [\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well000_axon_analytics_dvdt.csv\", \"Homo\"),\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well001_axon_analytics_dvdt.csv\", \"Homo\"),\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well002_axon_analytics_dvdt.csv\", \"Homo\"),\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well003_axon_analytics_dvdt.csv\", \"Het\"),\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well004_axon_analytics_dvdt.csv\", \"Het\"),\n",
    "                (\"/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240416/M08034/AxonTracking/000015/well005_axon_analytics_dvdt.csv\", \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV7\": {\n",
    "        \"T4\": {\n",
    "            #Recording may have failed here? TODO: Check\"\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well001_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well002_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well003_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240419/M08034/AxonTracking/000031/well005_axon_analytics_dvdt.csv', \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV10\": {\n",
    "        \"T3\": {\n",
    "            #TODO: Why is there missing data here?\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well001_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well002_axon_analytics_dvdt.csv', \"WT\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well003_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000025/well005_axon_analytics_dvdt.csv', \"WT\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV11\": {\n",
    "        \"T4\": {\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well001_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well002_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well003_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240423/M08034/AxonTracking/000043/well005_axon_analytics_dvdt.csv', \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV13\": {\n",
    "        \"T3\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000036/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240325/M07037/AxonTracking/000036/well001_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240325/M07037/AxonTracking/000036/well002_axon_analytics_dvdt.csv', \"WT\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000036/well003_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240325/M07037/AxonTracking/000036/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240325/M07037/AxonTracking/000036/well005_axon_analytics_dvdt.csv', \"WT\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV14\": {\n",
    "        \"T4\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well001_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well002_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well003_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240426/M08034/AxonTracking/000055/well005_axon_analytics_dvdt.csv', \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV16\": {\n",
    "        \"T3\": {\n",
    "            #TODO: Why is there missing data here?\n",
    "            \"files\": [\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000055/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240328/M07037/AxonTracking/000055/well001_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240328/M07037/AxonTracking/000055/well002_axon_analytics_dvdt.csv', \"WT\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240322/M07037/AxonTracking/000055/well003_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240328/M07037/AxonTracking/000055/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240328/M07037/AxonTracking/000055/well005_axon_analytics_dvdt.csv', \"WT\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV21\": {\n",
    "        \"T3\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000055/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000065/well001_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000065/well002_axon_analytics_dvdt.csv', \"WT\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000065/well003_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000065/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000065/well005_axon_analytics_dvdt.csv', \"WT\"),\n",
    "            ]\n",
    "        },\n",
    "        \"T4\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well001_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well002_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well003_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240503/M08034/AxonTracking/000082/well005_axon_analytics_dvdt.csv', \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV24\": {\n",
    "        \"T3\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000077/well000_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240405/M07037/AxonTracking/000077/well001_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240405/M07037/AxonTracking/000077/well002_axon_analytics_dvdt.csv', \"WT\"),\n",
    "                #('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240402/M07037/AxonTracking/000077/well003_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240405/M07037/AxonTracking/000077/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240405/M07037/AxonTracking/000077/well005_axon_analytics_dvdt.csv', \"WT\"),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"DIV25\": {\n",
    "        \"T4\": {\n",
    "            #TODO: Note why there are missing data here.\n",
    "            \"files\": [\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240507/M08034/AxonTracking/000094/well002_axon_analytics_dvdt.csv', \"Homo\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240507/M08034/AxonTracking/000094/well003_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240507/M08034/AxonTracking/000094/well004_axon_analytics_dvdt.csv', \"Het\"),\n",
    "                ('/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions_KCNT1/240507/M08034/AxonTracking/000094/well005_axon_analytics_dvdt.csv', \"Het\"),\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_paths = []\n",
    "categories = []\n",
    "divs = []\n",
    "\n",
    "for div, div_data in files_dict.items():\n",
    "    for t, t_data in div_data.items():\n",
    "        for file_path, category in t_data[\"files\"]:\n",
    "            file_paths.append(file_path)\n",
    "            categories.append(category)\n",
    "            divs.append(int(div[3:]))  # Extract the DIV number\n",
    "\n",
    "# Verify files exist\n",
    "for file in file_paths:\n",
    "    try:\n",
    "        assert os.path.exists(file), f\"File {file} does not exist\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "try: assert len(categories) == len(divs) == len(categories), \"Length of categories and DIVs must be equal to the number of files\"\n",
    "except AssertionError as e: \n",
    "    print(e)\n",
    "    print(len(categories), len(divs), len(file_paths))\n",
    "\n",
    "#Modify lists to exclude data based on position in categories\n",
    "#categories = [categories[i] for i in range(len(categories)) if categories[i] != 'HOM']\n",
    "#categories = [categories[i] for i in range(len(categories)) if categories[i] != 'HET']\n",
    "#categories = [categories[i] for i in range(len(categories)) if categories[i] != 'WT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with the given categories and DIVs\n",
    "#from AxonReconPipeline.src.lib_plotting_and_analysis import load_data\n",
    "#from AxonReconPipeline.src.lib_plot_and_analyze import load_data\n",
    "data = load_data(file_paths, categories, divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from AxonReconPipeline.src.lib_plotting_and_analysis import extract_branch_lengths, extract_branch_velocities, extract_number_of_branches\n",
    "# from AxonReconPipeline.src.lib_plotting_and_analysis import (\n",
    "#     validate_template_densities, \n",
    "#     #validate_branch_lengths_data, \n",
    "#     #validate_velocity_data,\n",
    "#     #validate_number_of_branches_data,\n",
    "#     count_all_units_and_branches,\n",
    "# )\n",
    "\n",
    "#template validation\n",
    "valid_data = validate_template_densities(data, threshold=0.75) #Arbitrary number. #TODO: Find a good threshold\n",
    "\n",
    "# Extract data\n",
    "branch_lengths_data = extract_branch_lengths(valid_data)\n",
    "branch_velocities_data = extract_branch_velocities(valid_data)\n",
    "#number_of_branches_data = extract_number_of_branches(valid_data)\n",
    "\n",
    "#validate data\n",
    "final_valid_data = combine_validations(valid_data, stddevs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data - dv/dt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from AxonReconPipeline.src.lib_plotting_and_analysis import plot_with_significance\n",
    "# from AxonReconPipeline.src.lib_plotting_and_analysis import validate_branch_lengths_data, validate_branch_velocities_data, validate_number_of_branches_data\n",
    "#from AxonReconPipeline.src.lib_plot_and_analyze import plot_velocities_by_gene\n",
    "\n",
    "# Plot data with significance annotations\n",
    "ax = plot_with_significance(final_valid_data, 'length', 'Branch Length Comparison by Category and DIV with Significance', 'Branch Length (µm)')\n",
    "ax.get_figure().savefig('branch_length_comparison.svg', format='svg')\n",
    "ax = plot_with_significance(final_valid_data, 'length', 'Branch Length Comparison by Category and DIV with Significance', 'Number of Branches', scatter=False)\n",
    "ax.get_figure().savefig('branch_length_comparison_noscatter.svg', format='svg')\n",
    "\n",
    "ax = plot_with_significance(final_valid_data, 'Velocity', 'Branch Velocity Comparison by Category and DIV with Significance', 'Branch Velocity (µm/ms)')\n",
    "ax.get_figure().savefig('branch_velocity_comparison.svg', format='svg') \n",
    "ax = plot_with_significance(final_valid_data, 'Velocity', 'Branch Velocity Comparison by Category and DIV with Significance', 'Branch Velocity (µm/ms)', scatter=False)\n",
    "ax.get_figure().savefig('branch_velocity_comparison_noscatter.svg', format='svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v(t) Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Select axon analytic .csv files to plot/compare'''\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''get current working directory, change it to project root directory'''\n",
    "os.getcwd()\n",
    "os.chdir('/home/adam/workspace/git_workspace/MEA_Analysis/')\n",
    "\n",
    "# Load the uploaded files into dataframes\n",
    "file_paths = [\n",
    "\n",
    "#DIV10\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well000_axon_analytics_template.csv', # DIV 10, Homozygous \n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well001_axon_analytics_template.csv', # DIV 10, Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well002_axon_analytics_template.csv', # DIV 10, WT\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well003_axon_analytics_template.csv', # DIV 10, Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well004_axon_analytics_template.csv', # DIV 10, Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000025/well005_axon_analytics_template.csv', # DIV 10, WT \n",
    "\n",
    "#DIV13\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000055/well000_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240325/M07037/AxonTracking/000036/well001_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240325/M07037/AxonTracking/000036/well002_axon_analytics_template.csv', # WT\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000055/well003_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240325/M07037/AxonTracking/000036/well004_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240325/M07037/AxonTracking/000036/well005_axon_analytics_template.csv', # WT\n",
    "\n",
    "#DIV16\n",
    "# '/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000055/well000_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240328/M07037/AxonTracking/000055/well001_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240328/M07037/AxonTracking/000055/well002_axon_analytics_template.csv', # WT\n",
    "# '/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240322/M07037/AxonTracking/000055/well003_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240328/M07037/AxonTracking/000055/well004_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240328/M07037/AxonTracking/000055/well005_axon_analytics_template.csv', # WT    \n",
    "\n",
    "#DIV21\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000055/well000_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000065/well001_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000065/well002_axon_analytics_template.csv', # WT\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000065/well003_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000065/well004_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000065/well005_axon_analytics_template.csv', # WT\n",
    "\n",
    "#DIV24\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000055/well000_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240405/M07037/AxonTracking/000077/well001_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240405/M07037/AxonTracking/000077/well002_axon_analytics_template.csv', # WT\n",
    "#'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240402/M07037/AxonTracking/000055/well003_axon_analytics_template.csv', # Homozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240405/M07037/AxonTracking/000077/well004_axon_analytics_template.csv', # Heterozygous\n",
    "'/home/adam/workspace/git_workspace/MEA_Analysis/AxonReconPipeline/data/reconstructions/240405/M07037/AxonTracking/000077/well005_axon_analytics_template.csv', # WT\n",
    "    \n",
    "]\n",
    "\n",
    "# Define corresponding categories and DIVs\n",
    "# categories = ['HET', 'WT', 'HET', 'WT', 'HET', 'WT', 'HET', 'WT','HET', 'WT']\n",
    "# divs = [10, 10, 10, 10, 13, 13, 13, 13, 16, 16]\n",
    "# assert len(categories) == len(divs), \"Number of categories and file paths must match\"\n",
    "\n",
    "# Load data with the given categories and DIVs\n",
    "from AxonReconPipeline.src.lib_plotting_and_analysis import load_data\n",
    "data = load_data(file_paths, categories, divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AxonReconPipeline.src.lib_plotting_and_analysis import extract_branch_lengths, extract_branch_velocities, extract_number_of_branches\n",
    "# Extract data\n",
    "branch_lengths_data = extract_branch_lengths(data)\n",
    "branch_velocities_data = extract_branch_velocities(data)\n",
    "number_of_branches_data = extract_number_of_branches(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AxonReconPipeline.src.lib_plotting_and_analysis import plot_with_significance\n",
    "# Plot data with significance annotations\n",
    "plot_with_significance(branch_lengths_data, 'Length', 'Branch Length Comparison by Category and DIV with Significance', 'Branch Length (µm)')\n",
    "#plot_with_significance(number_of_branches_data, 'Branches', 'Number of Branches Comparison by Category and DIV with Significance', 'Number of Branches')\n",
    "plot_with_significance(branch_velocities_data, 'Velocity', 'Branch Velocity Comparison by Category and DIV with Significance', 'Branch Velocity (µm/ms)')\n",
    "\n",
    "from AxonReconPipeline.src.lib_plotting_and_analysis import count_units_and_branches\n",
    "unit_counts_branches, branch_counts_branches = count_units_and_branches(number_of_branches_data)\n",
    "print(f\"Unit counts: {unit_counts_branches}\")\n",
    "print(f\"Branch counts: {branch_counts_branches}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
